{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"https://keras.io/img/logo-small.png\" alt=\"Keras logo\" width=\"100\"><br/>\n",
    "This starter notebook is provided by the Keras team.</center>\n",
    "\n",
    "## Keras NLP starter guide here: https://keras.io/guides/keras_nlp/getting_started/\n",
    "\n",
    "In this competition, the challenge is to build a machine learning model that predicts which Tweets are about real disasters and which one’s aren’t.\n",
    "A dataset of 10,000 tweets that were hand classified is available. \n",
    "\n",
    "__This starter notebook uses the [DistilBERT](https://arxiv.org/abs/1910.01108) pretrained model from KerasNLP.__\n",
    "\n",
    "\n",
    "**BERT** stands for **Bidirectional Encoder Representations from Transformers**. BERT and other Transformer encoder architectures have been wildly successful on a variety of tasks in NLP (natural language processing). They compute vector-space representations of natural language that are suitable for use in deep learning models.\n",
    "\n",
    "The BERT family of models uses the **Transformer encoder architecture** to process each token of input text in the full context of all tokens before and after, hence the name: Bidirectional Encoder Representations from Transformers.\n",
    "\n",
    "BERT models are usually pre-trained on a large corpus of text, then fine-tuned for specific tasks.\n",
    "\n",
    "**DistilBERT model** is a distilled form of the **BERT** model. The size of a BERT model was reduced by 40% via knowledge distillation during the pre-training phase while retaining 97% of its language understanding abilities and being 60% faster.\n",
    "\n",
    "\n",
    "\n",
    "![BERT Architecture](https://www.cse.chalmers.se/~richajo/nlp2019/l5/bert_class.png)\n",
    "\n",
    "\n",
    "\n",
    "In this notebook, you will:\n",
    "\n",
    "- Load the Disaster Tweets\n",
    "- Explore the dataset\n",
    "- Preprocess the data\n",
    "- Load a DistilBERT model from Keras NLP\n",
    "- Train your own model, fine-tuning BERT\n",
    "- Generate the submission file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-07-31T20:00:45.041191Z",
     "iopub.status.busy": "2023-07-31T20:00:45.040776Z",
     "iopub.status.idle": "2023-07-31T20:01:10.624768Z",
     "shell.execute_reply": "2023-07-31T20:01:10.623539Z",
     "shell.execute_reply.started": "2023-07-31T20:00:45.041149Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras-core in /opt/anaconda3/lib/python3.12/site-packages (0.1.7)\n",
      "Requirement already satisfied: absl-py in /opt/anaconda3/lib/python3.12/site-packages (from keras-core) (2.3.1)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.12/site-packages (from keras-core) (1.26.4)\n",
      "Requirement already satisfied: rich in /opt/anaconda3/lib/python3.12/site-packages (from keras-core) (13.7.1)\n",
      "Requirement already satisfied: namex in /opt/anaconda3/lib/python3.12/site-packages (from keras-core) (0.1.0)\n",
      "Requirement already satisfied: h5py in /opt/anaconda3/lib/python3.12/site-packages (from keras-core) (3.13.0)\n",
      "Requirement already satisfied: dm-tree in /opt/anaconda3/lib/python3.12/site-packages (from keras-core) (0.1.9)\n",
      "Requirement already satisfied: attrs>=18.2.0 in /Users/cindyli/.local/lib/python3.12/site-packages (from dm-tree->keras-core) (24.2.0)\n",
      "Requirement already satisfied: wrapt>=1.11.2 in /opt/anaconda3/lib/python3.12/site-packages (from dm-tree->keras-core) (1.14.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from rich->keras-core) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/cindyli/.local/lib/python3.12/site-packages (from rich->keras-core) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/anaconda3/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->keras-core) (0.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install keras-core --upgrade\n",
    "!pip install -q keras-nlp --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-31T20:01:10.62922Z",
     "iopub.status.busy": "2023-07-31T20:01:10.628924Z",
     "iopub.status.idle": "2023-07-31T20:01:20.556625Z",
     "shell.execute_reply": "2023-07-31T20:01:20.555665Z",
     "shell.execute_reply.started": "2023-07-31T20:01:10.629194Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/export/tf2onnx_lib.py:8: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
      "  if not hasattr(np, \"object\"):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend\n",
      "Tensorflow version: 2.19.1\n",
      "KerasNLP version: 0.25.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import tensorflow as tf\n",
    "#import keras_core as keras\n",
    "import keras\n",
    "import keras_nlp\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"Tensorflow version:\", torch.__version__)\n",
    "print(\"KerasNLP version:\", keras_nlp.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Disaster Tweets\n",
    "Let's have a look at the train and test dataset.\n",
    "\n",
    "They contain:\n",
    "- id\n",
    "- keyword: A keyword from that tweet (although this may be blank!)\n",
    "- location: The location the tweet was sent from (may also be blank)\n",
    "- text: The text of a tweet\n",
    "- target: 1 if the tweet is a real disaster or 0 if not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-31T20:01:20.558472Z",
     "iopub.status.busy": "2023-07-31T20:01:20.557857Z",
     "iopub.status.idle": "2023-07-31T20:01:20.62669Z",
     "shell.execute_reply": "2023-07-31T20:01:20.625756Z",
     "shell.execute_reply.started": "2023-07-31T20:01:20.558435Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Shape = (7613, 5)\n",
      "Training Set Memory Usage = 0.29 MB\n",
      "Test Set Shape = (3263, 4)\n",
      "Test Set Memory Usage = 0.10 MB\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv(\"data/train.csv\")\n",
    "df_test = pd.read_csv(\"data/test.csv\")\n",
    "\n",
    "print('Training Set Shape = {}'.format(df_train.shape))\n",
    "print('Training Set Memory Usage = {:.2f} MB'.format(df_train.memory_usage().sum() / 1024**2))\n",
    "print('Test Set Shape = {}'.format(df_test.shape))\n",
    "print('Test Set Memory Usage = {:.2f} MB'.format(df_test.memory_usage().sum() / 1024**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-31T20:01:20.629925Z",
     "iopub.status.busy": "2023-07-31T20:01:20.629651Z",
     "iopub.status.idle": "2023-07-31T20:01:20.646214Z",
     "shell.execute_reply": "2023-07-31T20:01:20.645286Z",
     "shell.execute_reply.started": "2023-07-31T20:01:20.6299Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-31T20:01:20.649765Z",
     "iopub.status.busy": "2023-07-31T20:01:20.649504Z",
     "iopub.status.idle": "2023-07-31T20:01:20.659375Z",
     "shell.execute_reply": "2023-07-31T20:01:20.658296Z",
     "shell.execute_reply.started": "2023-07-31T20:01:20.649741Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>there is a forest fire at spot pond, geese are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text\n",
       "0   0     NaN      NaN                 Just happened a terrible car crash\n",
       "1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n",
       "2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n",
       "3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n",
       "4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-31T20:01:20.661278Z",
     "iopub.status.busy": "2023-07-31T20:01:20.660532Z",
     "iopub.status.idle": "2023-07-31T20:01:20.686752Z",
     "shell.execute_reply": "2023-07-31T20:01:20.685851Z",
     "shell.execute_reply.started": "2023-07-31T20:01:20.661241Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Length Stat\n",
      "count    7613.000000\n",
      "mean      101.037436\n",
      "std        33.781325\n",
      "min         7.000000\n",
      "25%        78.000000\n",
      "50%       107.000000\n",
      "75%       133.000000\n",
      "max       157.000000\n",
      "Name: length, dtype: float64\n",
      "\n",
      "Test Length Stat\n",
      "count    3263.000000\n",
      "mean      102.108183\n",
      "std        33.972158\n",
      "min         5.000000\n",
      "25%        78.000000\n",
      "50%       109.000000\n",
      "75%       134.000000\n",
      "max       151.000000\n",
      "Name: length, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "df_train[\"length\"] = df_train[\"text\"].apply(lambda x : len(x))\n",
    "df_test[\"length\"] = df_test[\"text\"].apply(lambda x : len(x))\n",
    "\n",
    "print(\"Train Length Stat\")\n",
    "print(df_train[\"length\"].describe())\n",
    "print()\n",
    "\n",
    "print(\"Test Length Stat\")\n",
    "print(df_test[\"length\"].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to know more information about the data, you can grab useful information [here](https://www.kaggle.com/code/gunesevitan/nlp-with-disaster-tweets-eda-cleaning-and-bert)\n",
    "\n",
    "Note that all the tweets are in english."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-31T20:01:20.688711Z",
     "iopub.status.busy": "2023-07-31T20:01:20.688377Z",
     "iopub.status.idle": "2023-07-31T20:01:20.694731Z",
     "shell.execute_reply": "2023-07-31T20:01:20.693638Z",
     "shell.execute_reply.started": "2023-07-31T20:01:20.688679Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "NUM_TRAINING_EXAMPLES = df_train.shape[0]\n",
    "TRAIN_SPLIT = 0.8\n",
    "VAL_SPLIT = 0.2\n",
    "STEPS_PER_EPOCH = int(NUM_TRAINING_EXAMPLES)*TRAIN_SPLIT // BATCH_SIZE\n",
    "\n",
    "EPOCHS = 2\n",
    "AUTO = tf.data.experimental.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-31T20:01:20.697023Z",
     "iopub.status.busy": "2023-07-31T20:01:20.696116Z",
     "iopub.status.idle": "2023-07-31T20:01:20.717538Z",
     "shell.execute_reply": "2023-07-31T20:01:20.716665Z",
     "shell.execute_reply.started": "2023-07-31T20:01:20.696979Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df_train[\"text\"]\n",
    "y = df_train[\"target\"]\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=VAL_SPLIT, random_state=42)\n",
    "\n",
    "X_test = df_test[\"text\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load a DistilBERT model from Keras NLP\n",
    "\n",
    "Text inputs need to be transformed to numeric token ids and arranged in several Tensors before being input to BERT.\n",
    "\n",
    "The BertClassifier model can be configured with a preprocessor layer, in which case it will automatically apply preprocessing to raw inputs during fit(), predict(), and evaluate(). This is done by default when creating the model with from_preset().\n",
    "\n",
    "We will choose DistilBERT model.that learns a distilled (approximate) version of BERT, retaining 97% performance but using only half the number of parameters ([paper](https://arxiv.org/abs/1910.01108)). \n",
    "\n",
    "It has 40% less parameters than bert-base-uncased, runs 60% faster while preserving over 95% of BERT’s performances as measured on the GLUE language understanding benchmark.\n",
    "\n",
    "Specifically, it doesn't have token-type embeddings, pooler and retains only half of the layers from Google's BERT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-31T20:01:20.719649Z",
     "iopub.status.busy": "2023-07-31T20:01:20.719008Z",
     "iopub.status.idle": "2023-07-31T20:01:37.14406Z",
     "shell.execute_reply": "2023-07-31T20:01:37.142842Z",
     "shell.execute_reply.started": "2023-07-31T20:01:20.7196Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Preprocessor: \"preprocessor_4_tweets\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mPreprocessor: \"preprocessor_4_tweets\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                                                  </span>┃<span style=\"font-weight: bold\">                                   Config </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ distil_bert_tokenizer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DistilBertTokenizer</span>)                   │                       Vocab size: <span style=\"color: #00af00; text-decoration-color: #00af00\">30,522</span> │\n",
       "└───────────────────────────────────────────────────────────────┴──────────────────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                                                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m                                  Config\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ distil_bert_tokenizer (\u001b[38;5;33mDistilBertTokenizer\u001b[0m)                   │                       Vocab size: \u001b[38;5;34m30,522\u001b[0m │\n",
       "└───────────────────────────────────────────────────────────────┴──────────────────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"distil_bert_text_classifier\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"distil_bert_text_classifier\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ padding_mask (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ token_ids (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ distil_bert_backbone          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)         │      <span style=\"color: #00af00; text-decoration-color: #00af00\">66,362,880</span> │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DistilBertBackbone</span>)          │                           │                 │ token_ids[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ get_item (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GetItem</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ distil_bert_backbone[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ pooled_dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)               │         <span style=\"color: #00af00; text-decoration-color: #00af00\">590,592</span> │ get_item[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ output_dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ pooled_dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ logits (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,538</span> │ output_dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ padding_mask (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ token_ids (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ distil_bert_backbone          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)         │      \u001b[38;5;34m66,362,880\u001b[0m │ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n",
       "│ (\u001b[38;5;33mDistilBertBackbone\u001b[0m)          │                           │                 │ token_ids[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ get_item (\u001b[38;5;33mGetItem\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ distil_bert_backbone[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ pooled_dense (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)               │         \u001b[38;5;34m590,592\u001b[0m │ get_item[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ output_dropout (\u001b[38;5;33mDropout\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ pooled_dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ logits (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)                 │           \u001b[38;5;34m1,538\u001b[0m │ output_dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">66,955,010</span> (255.41 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m66,955,010\u001b[0m (255.41 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">66,955,010</span> (255.41 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m66,955,010\u001b[0m (255.41 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load a DistilBERT model.\n",
    "preset= \"distil_bert_base_en_uncased\"\n",
    "\n",
    "# Use a shorter sequence length.\n",
    "preprocessor = keras_nlp.models.DistilBertPreprocessor.from_preset(preset,\n",
    "                                                                   sequence_length=160,\n",
    "                                                                   name=\"preprocessor_4_tweets\"\n",
    "                                                                  )\n",
    "\n",
    "# Pretrained classifier.\n",
    "classifier = keras_nlp.models.DistilBertClassifier.from_preset(preset,\n",
    "                                                               preprocessor = preprocessor, \n",
    "                                                               num_classes=2)\n",
    "\n",
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train your own model, fine-tuning BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-31T20:01:37.146295Z",
     "iopub.status.busy": "2023-07-31T20:01:37.145916Z",
     "iopub.status.idle": "2023-07-31T20:04:19.910429Z",
     "shell.execute_reply": "2023-07-31T20:04:19.909408Z",
     "shell.execute_reply.started": "2023-07-31T20:01:37.146259Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Could not interpret optimizer identifier: <keras_core.src.optimizers.adam.Adam object at 0x336564500>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Compile\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mclassifier\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlosses\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSparseCategoricalCrossentropy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfrom_logits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m#'binary_crossentropy',\u001b[39;49;00m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAdam\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1e-5\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maccuracy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m  \u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Fit\u001b[39;00m\n\u001b[1;32m      9\u001b[0m history \u001b[38;5;241m=\u001b[39m classifier\u001b[38;5;241m.\u001b[39mfit(x\u001b[38;5;241m=\u001b[39mX_train,\n\u001b[1;32m     10\u001b[0m                          y\u001b[38;5;241m=\u001b[39my_train,\n\u001b[1;32m     11\u001b[0m                          batch_size\u001b[38;5;241m=\u001b[39mBATCH_SIZE,\n\u001b[1;32m     12\u001b[0m                          epochs\u001b[38;5;241m=\u001b[39mEPOCHS, \n\u001b[1;32m     13\u001b[0m                          validation_data\u001b[38;5;241m=\u001b[39m(X_val, y_val)\n\u001b[1;32m     14\u001b[0m                         )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/keras_hub/src/models/text_classifier.py:97\u001b[0m, in \u001b[0;36mTextClassifier.compile\u001b[0;34m(self, optimizer, loss, metrics, **kwargs)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m metrics \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     96\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m [keras\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39mSparseCategoricalAccuracy()]\n\u001b[0;32m---> 97\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetrics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/keras/src/optimizers/__init__.py:98\u001b[0m, in \u001b[0;36mget\u001b[0;34m(identifier)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, Optimizer):\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\n\u001b[0;32m---> 98\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not interpret optimizer identifier: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00midentifier\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Could not interpret optimizer identifier: <keras_core.src.optimizers.adam.Adam object at 0x336564500>"
     ]
    }
   ],
   "source": [
    "# Compile\n",
    "classifier.compile(\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True), #'binary_crossentropy',\n",
    "    optimizer=keras.optimizers.Adam(1e-5),\n",
    "    metrics= [\"accuracy\"]  \n",
    ")\n",
    "\n",
    "# Fit\n",
    "history = classifier.fit(x=X_train,\n",
    "                         y=y_train,\n",
    "                         batch_size=BATCH_SIZE,\n",
    "                         epochs=EPOCHS, \n",
    "                         validation_data=(X_val, y_val)\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-31T20:04:19.91385Z",
     "iopub.status.busy": "2023-07-31T20:04:19.913491Z",
     "iopub.status.idle": "2023-07-31T20:04:19.923256Z",
     "shell.execute_reply": "2023-07-31T20:04:19.922094Z",
     "shell.execute_reply.started": "2023-07-31T20:04:19.913815Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def displayConfusionMatrix(y_true, y_pred, dataset):\n",
    "    disp = ConfusionMatrixDisplay.from_predictions(\n",
    "        y_true,\n",
    "        np.argmax(y_pred, axis=1),\n",
    "        display_labels=[\"Not Disaster\",\"Disaster\"],\n",
    "        cmap=plt.cm.Blues\n",
    "    )\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, np.argmax(y_pred, axis=1)).ravel()\n",
    "    f1_score = tp / (tp+((fn+fp)/2))\n",
    "\n",
    "    disp.ax_.set_title(\"Confusion Matrix on \" + dataset + \" Dataset -- F1 Score: \" + str(f1_score.round(2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-31T20:04:19.925162Z",
     "iopub.status.busy": "2023-07-31T20:04:19.924738Z",
     "iopub.status.idle": "2023-07-31T20:05:04.197288Z",
     "shell.execute_reply": "2023-07-31T20:05:04.19632Z",
     "shell.execute_reply.started": "2023-07-31T20:04:19.925118Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "y_pred_train = classifier.predict(X_train)\n",
    "\n",
    "displayConfusionMatrix(y_train, y_pred_train, \"Training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-31T20:05:04.199632Z",
     "iopub.status.busy": "2023-07-31T20:05:04.198688Z",
     "iopub.status.idle": "2023-07-31T20:05:12.995278Z",
     "shell.execute_reply": "2023-07-31T20:05:12.994338Z",
     "shell.execute_reply.started": "2023-07-31T20:05:04.199591Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "y_pred_val = classifier.predict(X_val)\n",
    "\n",
    "displayConfusionMatrix(y_val, y_pred_val, \"Validation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate the submission file \n",
    "\n",
    "For each tweets in the test set, we predict if the given tweet is about a real disaster or not. If so, predict a 1. If not, predict a 0.\n",
    "\n",
    "The `submission.csv` file uses the following format:\n",
    "`id,target`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-31T20:05:13.000332Z",
     "iopub.status.busy": "2023-07-31T20:05:12.999248Z",
     "iopub.status.idle": "2023-07-31T20:05:13.023512Z",
     "shell.execute_reply": "2023-07-31T20:05:13.022432Z",
     "shell.execute_reply.started": "2023-07-31T20:05:13.000292Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv(\"/kaggle/input/nlp-getting-started/sample_submission.csv\")\n",
    "sample_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-31T20:05:13.025972Z",
     "iopub.status.busy": "2023-07-31T20:05:13.025189Z",
     "iopub.status.idle": "2023-07-31T20:05:28.765372Z",
     "shell.execute_reply": "2023-07-31T20:05:28.764404Z",
     "shell.execute_reply.started": "2023-07-31T20:05:13.025933Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "sample_submission[\"target\"] = np.argmax(classifier.predict(X_test), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-31T20:05:28.767064Z",
     "iopub.status.busy": "2023-07-31T20:05:28.766701Z",
     "iopub.status.idle": "2023-07-31T20:05:28.787427Z",
     "shell.execute_reply": "2023-07-31T20:05:28.786399Z",
     "shell.execute_reply.started": "2023-07-31T20:05:28.767029Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "sample_submission.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-31T20:05:28.789378Z",
     "iopub.status.busy": "2023-07-31T20:05:28.788974Z",
     "iopub.status.idle": "2023-07-31T20:05:28.803925Z",
     "shell.execute_reply": "2023-07-31T20:05:28.803021Z",
     "shell.execute_reply.started": "2023-07-31T20:05:28.78933Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "sample_submission.to_csv(\"submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 869809,
     "sourceId": 17777,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30527,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
